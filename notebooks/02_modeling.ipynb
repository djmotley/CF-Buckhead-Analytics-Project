{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93957b85",
   "metadata": {},
   "source": [
    "# CrossFit Retention Project — 02 Modeling\n",
    "Build a simple churn model to identify at-risk members using PushPress exports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9140dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "members = pd.read_csv(r\"/mnt/data/Members.csv\", parse_dates=[\"Join_Date\"])\n",
    "attendance = pd.read_csv(r\"/mnt/data/Attendance.csv\", parse_dates=[\"Date\"])\n",
    "sales = pd.read_csv(r\"/mnt/data/Store_Sales.csv\", parse_dates=[\"Purchase_Date\"])\n",
    "cancellations = pd.read_csv(r\"/mnt/data/Cancellations.csv\", parse_dates=[\"Cancel_Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b2f258",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a0a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snapshot date = most recent attendance date\n",
    "snapshot_date = attendance[\"Date\"].max()\n",
    "\n",
    "# Attendance-based features\n",
    "att_ok = attendance[attendance[\"Status\"].eq(\"Checked In\")].copy()\n",
    "last_seen = att_ok.groupby(\"Member_ID\")[\"Date\"].max().rename(\"Last_Checkin\")\n",
    "first_seen = att_ok.groupby(\"Member_ID\")[\"Date\"].min().rename(\"First_Checkin\")\n",
    "totals = att_ok.groupby(\"Member_ID\").size().rename(\"Total_Checkins\")\n",
    "by_month = att_ok.assign(month=att_ok[\"Date\"].dt.to_period(\"M\").dt.to_timestamp())\n",
    "visits_monthly = by_month.groupby([\"Member_ID\", \"month\"]).size().rename(\"Visits_Month\")\n",
    "\n",
    "# Variability of attendance\n",
    "var_att = visits_monthly.groupby(\"Member_ID\").std().rename(\"Visits_Month_STD\")\n",
    "\n",
    "# Recency + frequency\n",
    "feats = members.set_index(\"Member_ID\").join(last_seen).join(first_seen).join(totals).reset_index()\n",
    "feats[\"Days_Since_Last\"] = (snapshot_date - feats[\"Last_Checkin\"]).dt.days\n",
    "feats[\"Months_Active\"] = (\n",
    "    (feats[\"Last_Checkin\"].dt.to_period(\"M\") - feats[\"First_Checkin\"].dt.to_period(\"M\")).apply(\n",
    "        lambda p: p.n\n",
    "    )\n",
    "    + 1\n",
    ").clip(lower=1)\n",
    "feats[\"Visits_per_Month\"] = (feats[\"Total_Checkins\"] / feats[\"Months_Active\"]).fillna(0)\n",
    "\n",
    "# Retail spend\n",
    "spend = sales.groupby(\"Member_ID\")[\"Amount_USD\"].sum().rename(\"Retail_Spend_USD\")\n",
    "feats = feats.set_index(\"Member_ID\").join(spend).reset_index().fillna({\"Retail_Spend_USD\": 0})\n",
    "\n",
    "# Membership dummies\n",
    "feats = pd.get_dummies(feats, columns=[\"Membership_Type\", \"Referral_Source\"], drop_first=True)\n",
    "\n",
    "# Label churned (historical)\n",
    "churn_ids = set(cancellations[\"Member_ID\"])\n",
    "feats[\"Churned\"] = feats[\"Member_ID\"].isin(churn_ids).astype(int)\n",
    "\n",
    "# Fill remaining NaNs\n",
    "for col in [\"Days_Since_Last\", \"Visits_per_Month\", \"Visits_Month_STD\"]:\n",
    "    if col not in feats.columns:\n",
    "        feats[col] = np.nan\n",
    "feats = feats.set_index(\"Member_ID\").join(var_att).reset_index()\n",
    "feats[\"Visits_Month_STD\"] = feats[\"Visits_Month_STD\"].fillna(0)\n",
    "feats[\"Days_Since_Last\"] = feats[\"Days_Since_Last\"].fillna(\n",
    "    (snapshot_date - members[\"Join_Date\"].min()).days\n",
    ")\n",
    "feats[\"Visits_per_Month\"] = feats[\"Visits_per_Month\"].fillna(0)\n",
    "\n",
    "# Drop leakage columns\n",
    "drop_cols = [\"First_Checkin\", \"Last_Checkin\", \"Join_Date\"]\n",
    "feats = feats.drop(columns=[c for c in drop_cols if c in feats.columns])\n",
    "feats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d434168",
   "metadata": {},
   "source": [
    "## Train/Test Split & Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310be34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    PrecisionRecallDisplay,\n",
    "    RocCurveDisplay,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "target = \"Churned\"\n",
    "X = feats.drop(columns=[target])\n",
    "y = feats[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=2000)\n",
    "lr.fit(X_train, y_train)\n",
    "lr_probs = lr.predict_proba(X_test)[:, 1]\n",
    "lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "print(f\"Logistic ROC AUC: {lr_auc:.3f}\")\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_probs = rf.predict_proba(X_test)[:, 1]\n",
    "rf_auc = roc_auc_score(y_test, rf_probs)\n",
    "print(f\"RandomForest ROC AUC: {rf_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3ec069",
   "metadata": {},
   "source": [
    "## Curves (one plot per figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb117ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "RocCurveDisplay.from_predictions(y_test, lr_probs)\n",
    "plt.title(\"Logistic Regression ROC Curve\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test, rf_probs)\n",
    "plt.title(\"Random Forest ROC Curve\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "PrecisionRecallDisplay.from_predictions(y_test, lr_probs)\n",
    "plt.title(\"Logistic Regression Precision-Recall\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "PrecisionRecallDisplay.from_predictions(y_test, rf_probs)\n",
    "plt.title(\"Random Forest Precision-Recall\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bd07d6",
   "metadata": {},
   "source": [
    "## Thresholding & Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9d2fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "def evaluate_threshold(probs, y_true, threshold=0.5, title=\"Model\"):\n",
    "    preds = (probs >= threshold).astype(int)\n",
    "    print(title, \"Threshold:\", threshold)\n",
    "    print(classification_report(y_true, preds, digits=3))\n",
    "    cm = confusion_matrix(y_true, preds)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot()\n",
    "    plt.title(f\"{title} Confusion Matrix (thr={threshold})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "evaluate_threshold(rf_probs, y_test, threshold=0.4, title=\"Random Forest\")\n",
    "evaluate_threshold(lr_probs, y_test, threshold=0.4, title=\"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6956ba32",
   "metadata": {},
   "source": [
    "## Feature Importance & Top Risk List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7ec396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest feature importance\n",
    "import pandas as pd\n",
    "\n",
    "fi = pd.Series(rf.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "display(fi.head(15).to_frame(\"Importance\"))\n",
    "\n",
    "plt.figure()\n",
    "fi.head(15).sort_values().plot(kind=\"barh\")\n",
    "plt.title(\"Top Feature Importances (Random Forest)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create a scored list of current members (inference on whole set)\n",
    "rf_all_probs = rf.predict_proba(X)[:, 1]\n",
    "scored = feats.copy()\n",
    "scored[\"Churn_Risk_Score\"] = rf_all_probs\n",
    "# Example outreach list: the top 10 at-risk active members\n",
    "active_ids = set(members[\"Member_ID\"]) - set(cancellations[\"Member_ID\"])\n",
    "outreach = (\n",
    "    scored[scored[\"Member_ID\"].isin(active_ids)]\n",
    "    .sort_values(\"Churn_Risk_Score\", ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "display(\n",
    "    outreach[\n",
    "        [\"Member_ID\", \"Days_Since_Last\", \"Visits_per_Month\", \"Retail_Spend_USD\", \"Churn_Risk_Score\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4acfd1",
   "metadata": {},
   "source": [
    "### Notes for the Owner\n",
    "- Members with **high days since last visit** and **low visits per month** trend higher risk.\n",
    "- Consider personal coach outreach at 10–14 days inactive, plus a community nudge (buddy text, event invite)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
